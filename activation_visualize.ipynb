{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个MLP层中的神经元对每个tile分类的贡献，可以理解为该神经元对每个tile的激活程度。通过已经已经训练好的线性格子类别分类器，可以使用cosine similarity来计算每个神经元对每个tile的激活程度。\n",
    "如果神经元是正值，则认为该神经元对该tile的分类有贡献。如果神经元是负值，则认为该神经元对该tile的分类有抑制作用。\n",
    "此时，如果cosine similarity大于阈值，则认为该神经元对该tile的分类有贡献。\n",
    "- 因为输入是整个棋局的sequence，所以如果想预测每个tile的分类，需要在Transformer中计算每一个棋子的翻转，所以推断翻转次数越多的tiles在越靠后的层被激活。\n",
    "- 但是在Cosine Similarity中，没有对应的每个tile的翻转次数进行衡量，因为分析的是模型中神经元的表现，所以无法证明翻转次数的相关性。尝试使用SAE来衡量每个tile的翻转次数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dolphin\\miniconda3\\envs\\othello\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Dolphin\\miniconda3\\envs\\othello\\lib\\site-packages\\torchaudio\\backend\\utils.py:62: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "# Imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.dataloaders import get_dataloader\n",
    "import utils.dataloaders\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import analysis\n",
    "from neel_plotly import line, scatter, imshow, histogram\n",
    "# GPU acceleration\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved activation map for layer 1 to ./results/pics/cosim_results/9999_activation_map_layer_1.png\n",
      "Saved activation map for layer 2 to ./results/pics/cosim_results/9999_activation_map_layer_2.png\n",
      "Saved activation map for layer 3 to ./results/pics/cosim_results/9999_activation_map_layer_3.png\n",
      "Saved activation map for layer 4 to ./results/pics/cosim_results/9999_activation_map_layer_4.png\n",
      "Saved activation map for layer 5 to ./results/pics/cosim_results/9999_activation_map_layer_5.png\n",
      "Saved activation map for layer 6 to ./results/pics/cosim_results/9999_activation_map_layer_6.png\n",
      "Saved activation map for layer 7 to ./results/pics/cosim_results/9999_activation_map_layer_7.png\n",
      "Saved activation map for layer 8 to ./results/pics/cosim_results/9999_activation_map_layer_8.png\n"
     ]
    }
   ],
   "source": [
    "layers = list(range(0, 8))\n",
    "mode = 0 # [\"empty\", \"own\", \"enemy\"]\n",
    "seed = 9999\n",
    "threshold = 0.25\n",
    "save_path = True\n",
    "\n",
    "model_location = f\"trained_model_full_{seed}.pkl\"\n",
    "with open(model_location, 'rb') as f:\n",
    "    othello_gpt=torch.load(f, map_location=device)\n",
    "\n",
    "for layer in layers:\n",
    "    # Probe\n",
    "    probe_path = f\"probes/probe_layer_{layer}_{seed}_trimmed.pkl\"\n",
    "    full_linear_probe = torch.load(probe_path)\n",
    "    # print(full_linear_probe)\n",
    "    my_probe_W = full_linear_probe[f'classifier.{mode}.weight'] # (64, 512)\n",
    "    my_probe_W = my_probe_W.t()\n",
    "    # my_probe_W[:, [27, 28, 35, 36]] = 0.\n",
    "    my_probe_normalised = my_probe_W / my_probe_W.norm(dim=0, keepdim=True) # torch.Size([512, 64])\n",
    "    my_probe_normalised[my_probe_normalised.isnan()] = 0.\n",
    "\n",
    "    # Weight\n",
    "    weight_in_key = f\"blocks.{layer}.mlp_sublayer.encode.weight\"\n",
    "    \n",
    "    heatmaps_my = []\n",
    "    w_in = othello_gpt.state_dict()[weight_in_key] # torch.Size([512, 2048])\n",
    "    w_in /= w_in.norm(dim=0, keepdim=True)\n",
    "    for neuron in range(0, 2048):\n",
    "        neuron_weight = w_in[neuron, :]\n",
    "        heatmaps_my.append((neuron_weight[:, None] * my_probe_normalised).sum(dim=0))\n",
    "        \n",
    "    heatmaps_my = torch.stack(heatmaps_my) # (2048, 64)\n",
    "    \n",
    "    activation_map = (heatmaps_my.abs()>threshold).sum(dim=0)\n",
    "\n",
    "    activation_map = activation_map.reshape(8, 8).cpu().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    cax = ax.matshow(activation_map, cmap=\"viridis\", vmin=0, vmax=10)\n",
    "\n",
    "    plt.colorbar(cax)\n",
    "\n",
    "    \n",
    "    for (i, j), val in np.ndenumerate(activation_map):\n",
    "        ax.text(j, i, f\"{val}\", ha='center', va='center', color='white' if val <= 5 else 'black')\n",
    "\n",
    "    plt.title(f\"Activation map of layer {layer+1}\")\n",
    "    \n",
    "    ax.set_xticks(range(8))\n",
    "    ax.set_yticks(range(8))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    \n",
    "    if save_path:\n",
    "        if not os.path.exists(\"./results/pics/cosim_results\"):\n",
    "            os.makedirs(\"./results/pics/cosim_results\")\n",
    "        save_file = f\"./results/pics/cosim_results/{seed}_activation_map_layer_{layer+1}.png\"\n",
    "        plt.savefig(save_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved activation map for layer {layer+1} to {save_file}\")\n",
    "\n",
    "    plt.close(fig)  # Close the figure to free memory\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
